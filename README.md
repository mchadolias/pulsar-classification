# ğŸŒŒ Pulsar Star Classification Project

## ğŸ“‹ Project Overview

This project focuses on classifying pulsar stars using the HTRU2 dataset from Kaggle. Pulsars are rare and valuable astronomical objects, and accurate classification is crucial for astronomical research. The project implements a complete machine learning pipeline from data acquisition to model deployment.

### ğŸ¯ Business Problem

Pulsars are rare neutron stars that produce valuable scientific data. Manual classification is time-consuming and prone to error. This project aims to automate pulsar classification using machine learning to assist astronomers in identifying genuine pulsar signals from noise.

### ğŸ“Š Dataset

- **Source**: [HTRU2 Dataset from Kaggle](https://www.kaggle.com/datasets/charitarth/pulsar-dataset-htru2)
- **Samples**: 17,898 total instances
- **Features**: 8 numerical features derived from pulsar candidate profiles
- **Target**: Binary classification (0 = non-pulsar, 1 = pulsar)
- **Class Distribution**: Highly imbalanced (~90.84% non-pulsars, ~9.16% pulsars)

## ğŸ—ï¸ Project Structure

```markdown
pulsar_classification/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ main.py                 # Main pipeline execution script
â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ data_handler.py        # Data download, loading, and preprocessing
â”‚   â”œâ”€â”€ training.py            # Model training and evaluation
â”‚   â””â”€â”€ setup_directories.py   # Directory setup utility
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                # Saved trained models
â”‚   â”œâ”€â”€ metrics/               # Evaluation metrics and results
â”‚   â””â”€â”€ predictions/           # Prediction outputs
â”œâ”€â”€ logs/                      # Execution logs with timestamps
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/              # Raw downloaded data
â”‚   â””â”€â”€ processed/             # Processed and split data
â”œâ”€â”€ config/
â”‚   â””â”€â”€ training_config.toml   # Model configuration
â””â”€â”€ model_config.toml          # Hyperparameter configuration
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- UV package manager
- Kaggle API credentials

### Installation

1. **Clone the repository**

   ```bash
   git clone <repository-url>
   cd pulsar_classification
   ```

2. **Set up Kaggle API**

   ```bash
   mkdir -p ~/.kaggle
   cp kaggle.json ~/.kaggle/
   chmod 600 ~/.kaggle/kaggle.json
   ```

3. **Install dependencies**

   ```bash
   uv sync
   ```

4. **Set up directories**

   ```bash
   uv run python scripts/setup_directories.py
   ```

### Usage

Run the complete pipeline:

```bash
uv run python scripts/main.py
```

## âš™ï¸ Configuration

### Model Configuration (`model_config.toml`)

The project uses TOML configuration for model hyperparameters:

```toml
[logistic_regression]
max_iter = 500
solver = "lbfgs"
penalty = "l2"

[random_forest]
n_estimators = 200
max_depth = 10
class_weight = "balanced"

# ... additional model configurations
```

### Data Configuration (`scripts/config.py`)

- Data directory structure
- Split ratios (train/validation/test)
- Random seeds for reproducibility

## ğŸ”§ Features

### Data Pipeline

- **Automated Download**: Fetches dataset from Kaggle API
- **Data Validation**: Checks for missing values and data quality
- **Preprocessing**: Column renaming, numerical rounding, standardization
- **Stratified Splitting**: Maintains class distribution across splits

### Model Training

- **Multiple Algorithms**: Logistic Regression, Random Forest, Gradient Boosting, XGBoost
- **Hyperparameter Tuning**: GridSearchCV with cross-validation
- **Automated Evaluation**: ROC-AUC, Recall, F1-Score, Confusion Matrix
- **Feature Importance**: Model interpretability analysis

### Logging & Monitoring

- **Comprehensive Logging**: All operations logged to file and terminal
- **Timestamped Logs**: Automatic log file creation with timestamps
- **Error Handling**: Detailed error messages with stack traces
- **Progress Tracking**: Real-time progress updates

### Output Management

- **Model Persistence**: Saved models in pickle format
- **Metrics Export**: JSON and CSV formats for all evaluation metrics
- **Prediction Storage**: Test predictions with probabilities
- **Configuration Backup**: Training configuration preserved

## ğŸ“ˆ Model Performance

### Performance Summary

| Model | ROC-AUC | Recall | F1-Score | Training Time | Best Parameters |
|-------|---------|--------|----------|---------------|-----------------|
| **XGBoost** | **0.9768** | **0.8628** | **0.8927** | ~32 seconds | `learning_rate: 0.05`, `max_depth: 3`, `n_estimators: 200` |
| Logistic Regression | 0.9746 | 0.7774 | 0.8500 | ~2 seconds | `C: 1.0`, `penalty: l2` |
| Random Forest | 0.9738 | 0.8476 | 0.8701 | ~31 seconds | `max_depth: 10`, `min_samples_split: 2`, `n_estimators: 200` |
| Gradient Boosting | 0.9742 | 0.8049 | 0.8656 | ~52 seconds | `learning_rate: 0.05`, `max_depth: 3`, `n_estimators: 200` |

### Best Model Selection

- **Selected Model**: **XGBoost**
- **Selection Criteria**: Highest ROC-AUC score on validation set (0.9779)
- **Final Test Performance**: ROC-AUC 0.9768, Recall 0.8628, F1-Score 0.8927

### Feature Importance

**Top features contributing to pulsar classification:**

1. **ip_kurtosis**: 0.4368 (Integrated Profile Kurtosis)
2. **ip_skewness**: 0.3520 (Integrated Profile Skewness)
3. **dm_std**: 0.0678 (DM-SNR Curve Standard Deviation)
4. **ip_std**: 0.0412 (Integrated Profile Standard Deviation)
5. **ip_mean**: 0.0298 (Integrated Profile Mean)

### Confusion Matrix Analysis (XGBoost - Test Set)

```markdown
[[3229   23]
 [  45  283]]
```

**Performance Analysis:**

- **True Positives**: 283 pulsars correctly identified
- **True Negatives**: 3229 non-pulsars correctly identified  
- **False Positives**: 23 non-pulsars misclassified as pulsars
- **False Negatives**: 45 pulsars missed

**Key Metrics:**

- **Accuracy**: 98.1%
- **Precision**: 92.5%
- **Recall**: 86.3%
- **F1-Score**: 89.3%

## âš¡ Performance Validation

**Dataset Characteristics:**

- **Small Size**: 17,898 samples Ã— 8 features = 143,184 data points total
- **Low Dimensionality**: Only 8 features reduces computational complexity
- **Structured Data**: Clean, numerical data without missing values

**Computational Efficiency:**

- **Parallel Processing**: GridSearchCV used 8-fold CV with full CPU utilization
- **Optimized Libraries**: scikit-learn and XGBoost are highly optimized C++ implementations
- **Simple Models**: No deep learning or complex architectures

### Quality Assurance Steps Taken

1. **Stratified Splitting**: Maintained class distribution (90.84%/9.16%)
2. **Cross-Validation**: 8-fold CV ensures robust hyperparameter tuning
3. **Train-Validation-Test Split**: Proper evaluation protocol
4. **Multiple Algorithms**: Consistent performance across different model types
5. **Feature Importance**: Results align with domain knowledge (IP statistics most important)

## ğŸ¯ Key Features Implementation

### Data Handling

- **Class**: `HTRU2DataHandler`
- **Methods**: Download, load, preprocess, split, export
- **Error Handling**: Missing file detection, data validation

### Model Training

- **Class**: `ModelTrainer`
- **Algorithms**: 4 different classifiers with hyperparameter tuning
- **Evaluation**: Comprehensive metrics and cross-validation

### Configuration Management

- **Pydantic Settings**: Environment variable support
- **TOML Config**: Model hyperparameters and training settings
- **Reproducibility**: Fixed random seeds and version tracking

## ğŸ“Š Dataset Features

The HTRU2 dataset contains 8 features derived from the integrated pulse profile and DM-SNR curve:

1. **Integrated Profile Features**:
   - `ip_mean`: Mean of the integrated profile
   - `ip_std`: Standard deviation of the integrated profile
   - `ip_kurtosis`: Kurtosis of the integrated profile
   - `ip_skewness`: Skewness of the integrated profile

2. **DM-SNR Curve Features**:
   - `dm_mean`: Mean of the DM-SNR curve
   - `dm_std`: Standard deviation of the DM-SNR curve
   - `dm_kurtosis`: Kurtosis of the DM-SNR curve
   - `dm_skewness`: Skewness of the DM-SNR curve

3. **Target**:
   - `signal`: Class label (0: noise, 1: pulsar)

## ğŸ” Model Interpretation

### Business Impact

- **Recall Focus**: The model achieves 86.3% recall, meaning it correctly identifies 86.3% of actual pulsars
- **Precision Consideration**: With 92.5% precision, only 7.5% of predicted pulsars are false positives
- **Scientific Value**: The model significantly reduces manual verification workload while maintaining high detection rates

### Technical Considerations

- **Class Imbalance**: Successfully handled 9:1 class ratio through stratified sampling
- **Feature Scaling**: Standardization improved performance of distance-based algorithms
- **Model Calibration**: XGBoost provided well-calibrated probability estimates

### Performance Insights

1. **XGBoost Dominance**: Outperformed other models in both ROC-AUC and F1-score
2. **Feature Importance**: Integrated profile statistics (kurtosis, skewness) are most predictive
3. **Training Efficiency**: All models trained in under 1 minute total
4. **Cross-Validation**: 8-fold CV provided robust hyperparameter tuning

## ğŸš€ Pipeline Execution Summary

### Data Processing

- **Dataset Size**: 17,898 samples successfully processed
- **Data Quality**: No missing values detected
- **Splits**: 60% train (10,738), 20% validation (3,580), 20% test (3,580)
- **Class Balance**: Maintained across all splits

### Model Training

- **Total Training Time**: ~2 minutes for all 4 models
- **Hyperparameter Tuning**: GridSearchCV with 8-fold cross-validation
- **Best Validation Score**: XGBoost achieved 0.9797 ROC-AUC

### Output Generation

- **Saved Model**: `outputs/models/best_xgboost_model.pkl`
- **Metrics**: Comprehensive JSON and CSV files in `outputs/metrics/`
- **Predictions**: Test set predictions with probabilities saved
- **Logs**: Complete execution log with timestamps

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“š References

1. [HTRU2 Dataset Repository (UC Irvine)](https://archive.ics.uci.edu/dataset/372/htru2)
2. [Lyon, R. J., Stappers, B. W., et al. - Pulsar Classification](https://ui.adsabs.harvard.edu/abs/2016MNRAS.459.1104L)
3. [Kaggle Pulsar Dataset](https://www.kaggle.com/datasets/charitarth/pulsar-dataset-htru2)

## ğŸ†˜ Troubleshooting

### Common Issues

1. **Kaggle API Errors**
   - Verify `kaggle.json` credentials
   - Check internet connection
   - Ensure dataset is publicly accessible

2. **Dependency Conflicts**
   - Use UV for isolated environments
   - Check Python version compatibility
   - Review dependency versions in `pyproject.toml`

### Performance Tips

- The pipeline is optimized for efficiency, completing in under 3 minutes
- For larger datasets, consider reducing cross-validation folds
- Model training can be parallelized by adjusting `n_jobs` parameter

---

*Last Updated: 2025-11-18*  
*Last Pipeline Execution: 2025-11-18 01:33:06*  
*Best Model: XGBoost (ROC-AUC: 0.9768)*
